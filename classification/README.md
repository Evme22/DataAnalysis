# Data Classification: Logistic Regression & KNN & Decision Tree Classifier & Random Forest Classifier

## Содержание
- [Описание задания](#описание-задания)
- [Цели](#цели)
- [Выполненные шаги](#выполненные-шаги)
- [Используемые технологии](#используемые-технологии)
- [Результаты](#результаты)

## Описание задания
Проект направлен на исследование алгоритмов классификации в задаче прогнозирования наличия сердечных заболеваний на основе медицинских показателей. Реализовано сравнение двух базовых алгоритмов, логистической регрессии, k-ближайших соседей (KNN), дерево решений, случайный лес. 

## Цели
- Загрузить и предварительно обработать набор данных о сердечно-сосудистых заболеваниях 1heart.csv.
- Обучить и сравнить четыре модели классификации:
  - Logistic Regression;
  - Decision Tree;
  - Random Forest;
  - K-Nearest Neighbors.
- Проанализировать производительность моделей на тестовой выборке.
- Построить ROC-кривые, confusion matrix и графики точности для интерпретации результатов.

## Выполненные шаги
- Загрузка и предварительное изучение датасета 1heart.csv.
- Очистка и предварительная обработка данных.
- Кодирование категориальных признаков (OneHotEncoder()).
- Масштабирование числовых признаков (StandardScaler()).
- Разделение выборки на тренировочную и тестовую (train_test_split).
- Обучение следующих моделей:
  - Logistic Regression;
  - Decision Tree Classifier;
  - Random Forest Classifier;
  - K-Nearest Neighbors.
- Оценка моделей по метрикам: accuracy, precision, recall, F1-score.
- Построение confusion matrix, ROC-кривых и графиков важности признаков.
- Сравнительный анализ моделей и визуальное представление предсказаний.

Выполненные шаги и результаты отработанных методов можно посмотреть в файле classification-models.ipynb или в Google Colab по ссылке ниже.

## Используемые технологии
- Python 3
- Библиотеки:
  - pandas;
  - seaborn;
  - matplotlib.pyplot;
  - sklearn.preprocessing;
  - sklearn.compose;
  - sklearn.model_selection;
  - sklearn.preprocessing;
  - sklearn.neighbors;
  - sklearn.metrics;
  - sklearn.tree;
  - sklearn.linear_model;
  - sklearn.ensemble;
- Google Colab

[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)]
(https://colab.research.google.com/drive/1MHDlbNrG6DZoThTs7HFOVbZfEMHrlzNE?usp=sharing)

## Результаты
В рамках выполнения лабораторной работы были загружены данные, выполнен вывод первых 5 строк и общая информация о структуре датасета. Это позволило оценить типы данных, количество строк и столбцов, а также выявить наличие пропущенных значений и дубликатов. Проведена очистка данных, обработаны пропущенные значения, устранены явные и неявные дубликаты. Выполнена проверка статистических характеристик числовых столбцов. Выявлены выбросы, такие как некорректные значения артериального давления, уровня холестерина и изменения ST-сегмента. Эти значения были скорректированы. Выделена целевая переменная HeartDisease, указывающая на наличие заболевания.

На основе прошедшего предварительную обработку датасете были созданы и обучены модели k-ближайших соседей, дерево решений, логистическая регрессия, случайный лес. Выполнены предсказания моделей. 

Для каждой модели были рассчитаны метрики качества, включая точность, полноту, F1-меру. Модель случайного леса показала лучшие результаты по метрикам Accuracy (0.87) и F1-мера (0.89), демонстрируя сбалансированность и высокое качество классификации. Логистическая регрессия и метод k-ближайших соседей показали схожие результаты логистическая регрессия лидирует по точности (0.91), а метод k-ближайших соседей – по полноте (0.871). Дерево решений уступает по всем показателям, даже после оптимизации параметров. В целом, случайный лес выделяется как наиболее эффективный метод. 

Также были построены ROC-кривые. ROC-кривые позволили оценить способность моделей различать положительные и отрицательные классы на разных порогах вероятностей. Логистическая регрессия и случайный лес продемонстрировали наивысшее качество, достигнув значения AUC = 0.93. Модель k-ближайших соседей менее эффективна (AUC = 0.92), однако показала стабильные результаты. Дерево решений продемонстрировало наименьшую эффективность с AUC = 0.90. 

Результаты позволили сделать вывод о том, что методы случайный лес и логистическая регрессия являются предпочтительными для решения задачи классификации в рамках данной работы.
